{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install plotly-express\n",
    "%pip install --upgrade nbformat\n",
    "%pip install ipykernel\n",
    "%pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_map_point_state = pd.read_csv(\"training_data/fact_map_point_state.tsv\", sep=\"\\t\", index_col=[\"time\", \"map_point_id\"])\n",
    "fact_map_point_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_step = pd.read_csv(\"training_data/fact_step.tsv\", sep=\"\\t\", index_col=[\"start_time\", \"robot_id\"])\n",
    "fact_step.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_memory_map_point = pd.read_csv(\"training_data/fact_memory_map_point.tsv\", sep=\"\\t\", index_col=[\"time\", \"robot_id\", \"x\", \"y\"])\n",
    "fact_memory_map_point.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dym_map_point = pd.read_csv(\"training_data/dym_map_point.tsv\", sep=\"\\t\", index_col=[\"id\"])\n",
    "dym_map_point.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dym_robot = pd.read_csv(\"training_data/dym_robot.tsv\", sep=\"\\t\", index_col=[\"id\"])\n",
    "dym_robot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain_colors = {\n",
    "    'Free': 'white',\n",
    "    'Fire': 'red',\n",
    "    'Base': 'blue',\n",
    "    'OccupiedByRobot': 'gray',\n",
    "    'Obstacle': 'brown',\n",
    "    'OccupiedByItem': 'green',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBOT_ID = 10\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "robot_steps = fact_memory_map_point.loc[idx[:, ROBOT_ID, :, :]]\n",
    "\n",
    "fig = px.scatter(robot_steps,\n",
    "    x=robot_steps.index.get_level_values(\"x\"), \n",
    "    y=robot_steps.index.get_level_values(\"y\"), \n",
    "    color='terrain_type', \n",
    "    animation_frame=robot_steps.index.get_level_values(\"time\"),\n",
    "    title='Robot Map Memory Over Time',\n",
    "    labels={'x': 'X Coordinate', 'y': 'Y Coordinate'},\n",
    "    size_max=10,\n",
    "    color_discrete_map=terrain_colors,\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis=dict(range=[0, 50], title=\"X Coordinate\", showgrid=False, zeroline=False),\n",
    "    yaxis=dict(range=[0, 50], title=\"Y Coordinate\", showgrid=False, zeroline=False),\n",
    "    legend_title=\"Terrain Type\",\n",
    "    width=600,\n",
    "    height=600,\n",
    "    title_x=0.5,\n",
    "    plot_bgcolor=\"black\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_orientation(line):\n",
    "    if line[\"measured_orientation\"] == line[\"real_orientation\"]:\n",
    "        return 0\n",
    "    if ((line[\"measured_orientation\"] in [\"Up\", \"Down\"]\n",
    "        and line[\"real_orientation\"] in [\"Up\", \"Down\"])\n",
    "        or (line[\"measured_orientation\"] in [\"Left\", \"Right\"]\n",
    "        and line[\"real_orientation\"] in [\"Left\", \"Right\"])):\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "def process_raw_input_data(base_x, base_y, step_table):\n",
    "    processed_input = pd.DataFrame(index=step_table.index)\n",
    "\n",
    "    processed_input[\"action\"] = step_table[\"decided_action\"].replace({\n",
    "        \"StepForward\": 0,\n",
    "        \"GraspAnItem\": 1,\n",
    "        \"TurnRight\": 2,\n",
    "        \"TurnLeft\": 3,\n",
    "        \"Destroy\": 4,\n",
    "        \"StartFire\": 5,\n",
    "        \"PutDownAnItem\": 6,\n",
    "        \"DoNothing\": 7,\n",
    "    }).astype(int)\n",
    "\n",
    "    processed_input[\"gps_difference\"] = abs(step_table[\"measured_gps_x\"] - step_table[\"real_gps_x\"]) + abs(step_table[\"measured_gps_y\"] - step_table[\"real_gps_y\"])\n",
    "\n",
    "    processed_input[\"orientation_difference\"] = step_table.apply(compare_orientation, axis=1)\n",
    "\n",
    "    processed_input[\"lidar_difference\"] = abs(step_table[\"measured_lidar_distance\"] - step_table[\"real_distance\"])\n",
    "    processed_input[\"radar_difference\"] = abs(step_table[\"measured_radar_distance\"] - step_table[\"real_distance\"])\n",
    "    processed_input[\"thermometer_difference\"] = abs(step_table[\"measured_temperature\"] - step_table[\"real_temperature\"])\n",
    "\n",
    "    processed_input[\"cardinality_base_distance\"] = (abs(step_table[\"real_gps_x\"] - base_x) + abs(step_table[\"real_gps_y\"] - base_y)) / step_table[\"cardinality\"]\n",
    "\n",
    "    processed_input[\"action_successful\"] = step_table.apply(lambda row: 1 if row[\"action_successful\"] else 0, axis=1)\n",
    "\n",
    "    return processed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_X = 7\n",
    "BASE_Y = 12\n",
    "\n",
    "processed_input = process_raw_input_data(BASE_X, BASE_Y, fact_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Trustor's Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trustor_knowledge(dataset, map_state_table, map_point_table, memory_map_table):\n",
    "    real_map = map_state_table.join(map_point_table, on=\"map_point_id\").reset_index()[[\"time\", \"x\", \"y\", \"terrain_type\"]].set_index([\"time\", \"x\", \"y\"])\n",
    "\n",
    "    idx = pd.IndexSlice\n",
    "    def difference(memory):\n",
    "        memory = memory.reset_index()\n",
    "        different = memory[memory.apply(lambda row: real_map.at[(row[\"time\"], row[\"x\"], row[\"y\"]), \"terrain_type\"] != row[\"terrain_type\"], axis=1)]\n",
    "        memory_overlap_coeff = 0.5 + 0.5 * memory[\"terrain_type\"].count() / real_map.loc[idx[0, :, :]][\"terrain_type\"].count()\n",
    "        memory_difference = different[\"terrain_type\"].count() / memory[\"terrain_type\"].count()\n",
    "\n",
    "        return 1 - (memory_difference * memory_overlap_coeff)\n",
    "\n",
    "    dataset[\"memory_similarity\"] = memory_map_table.groupby(level=[0, 1]).apply(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_trustor_knowledge(processed_input, fact_map_point_state, dym_map_point, fact_memory_map_point)\n",
    "processed_input.to_csv(\"clean_training_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_input[\"profile\"] = processed_input.apply(\n",
    "    lambda row: dym_robot.at[row.name[1], \"profile\"], axis=1\n",
    ").replace({\n",
    "    \"Normal\": 0,\n",
    "    \"Broken\": 1,\n",
    "    \"ItemDestroyer\": 2,\n",
    "    \"Liar\": 3,\n",
    "    \"Arsonist\": 4\n",
    "}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_input = pd.read_csv(\"clean_training_data.csv\", index_col=[\"robot_id\", \"start_time\"])\n",
    "past_experience = pd.DataFrame(index=processed_input.index)\n",
    "past_experience[\"mission_experience\"] = 0.5\n",
    "past_experience[\"information_experience\"] = 0.5\n",
    "past_experience[\"behavior_experience\"] = 0.5\n",
    "past_experience[\"change_coeff\"] = 1\n",
    "past_experience.sort_index(inplace=True)\n",
    "\n",
    "past_experience[\"change_coeff\"] = 0.99 ** past_experience[\"change_coeff\"].groupby(level=0).expanding().sum().values\n",
    "all_raw = past_experience.join(processed_input).join(fact_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_behavior_experience(row):\n",
    "    if row[\"decided_action\"] == \"StartFire\":\n",
    "        return 0\n",
    "    if row[\"decided_action\"] == \"PutDownAnItem\":\n",
    "        return 1\n",
    "    return 0.5\n",
    "\n",
    "\n",
    "def update_information_experience(row):\n",
    "    return max(0, 1 - row[\"orientation_difference\"] / 10 - row[\"gps_difference\"] / 10 - row[\"lidar_difference\"] / 20 - row[\"radar_difference\"] / 20 - row[\"thermometer_difference\"] / 10)\n",
    "\n",
    "\n",
    "def update_mission_experience(row):\n",
    "    return 0.5 if np.isnan(row[\"cardinality_base_distance\"]) else max(0, 1 - max(0, row[\"cardinality_base_distance\"] - 8) / 10)\n",
    "\n",
    "past_experience[\"mission_experience\"] = 0.3 + 0.7 * all_raw.apply(update_mission_experience, axis=1)\n",
    "past_experience[\"information_experience\"] = 0.3 + 0.7 * all_raw.apply(update_information_experience, axis=1)\n",
    "past_experience[\"behavior_experience\"] = 0.3 + 0.7 * all_raw.apply(update_behavior_experience, axis=1)\n",
    "\n",
    "past_experience = past_experience.groupby(level=0).rolling(window=5, min_periods=1, closed=\"right\").mean()\n",
    "past_experience.reset_index(level=1, inplace=True)\n",
    "past_experience.drop(columns=[\"robot_id\"], inplace=True)\n",
    "\n",
    "past_experience = past_experience.groupby(level=0).rolling(window=20, min_periods=1, closed=\"right\").min()\n",
    "past_experience.reset_index(level=1, inplace=True)\n",
    "past_experience.drop(columns=[\"robot_id\"], inplace=True)\n",
    "\n",
    "past_experience = past_experience.groupby(level=0).ewm(alpha=2/3).mean()\n",
    "past_experience.reset_index(level=1, inplace=True)\n",
    "past_experience.drop(columns=[\"robot_id\"], inplace=True)\n",
    "\n",
    "past_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_experiences = past_experience.copy()\n",
    "train_experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_experience = past_experience.groupby(level=0).shift(1).dropna()\n",
    "past_experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (past_experience.join(processed_input)\n",
    "      .join(train_experiences, lsuffix=\"_past\")\n",
    "      .reset_index()\n",
    "      .drop(columns=[\"start_time\", \"robot_id\", \"change_coeff_past\", \"profile\"]))\n",
    "\n",
    "train_df = df.sample(frac=0.8, random_state=13)\n",
    "test_df = df.drop(train_df.index)\n",
    "\n",
    "train_X = train_df.copy()\n",
    "test_X = test_df.copy()\n",
    "\n",
    "train_Y = np.array(train_X[[\"mission_experience\", \"information_experience\", \"behavior_experience\"]],\n",
    "                   dtype=\"float32\")\n",
    "test_Y = np.array(test_X[[\"mission_experience\", \"information_experience\", \"behavior_experience\"]],\n",
    "                  dtype=\"float32\")\n",
    "\n",
    "train_X.drop(columns=[\"mission_experience\", \"information_experience\", \"behavior_experience\"],\n",
    "             inplace=True)\n",
    "test_X.drop(columns=[\"mission_experience\", \"information_experience\", \"behavior_experience\"],\n",
    "            inplace=True)\n",
    "\n",
    "train_X = np.array(train_X, dtype=\"float32\")\n",
    "test_X = np.array(test_X, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class TrustVectorEstimator(BaseEstimator):\n",
    "    def __init__(self, vector_size):\n",
    "        super().__init__()\n",
    "        self.vector_size = vector_size\n",
    "        self.trees = [DecisionTreeRegressor(max_depth=5) for _ in range(vector_size)]\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            tree.fit(X, Y[:, i])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.vstack([tree.predict(X) for tree in self.trees]).T\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        predicted_Y = self.predict(X)\n",
    "        return r2_score(Y, predicted_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = make_pipeline(StandardScaler(), TrustVectorEstimator(3))\n",
    "model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predicted_Y = model.predict(test_X)\n",
    "print(r2_score(test_Y, predicted_Y))\n",
    "print(mean_squared_error(test_Y, predicted_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "dict(zip(df.columns, permutation_importance(model, test_X, test_Y).importances_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect Trust Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peer_train_df = df.sample(frac=0.8, random_state=19)\n",
    "peer_test_df = df.drop(peer_train_df.index)\n",
    "\n",
    "peer_train_X = peer_train_df.copy()\n",
    "peer_test_X = peer_test_df.copy()\n",
    "\n",
    "peer_train_Y = np.array(peer_train_X[[\"mission_experience\", \"information_experience\", \"behavior_experience\"]], dtype=\"float32\")\n",
    "peer_test_Y = np.array(peer_test_X[[\"mission_experience\", \"information_experience\", \"behavior_experience\"]], dtype=\"float32\")\n",
    "\n",
    "peer_train_X.drop(columns=[\"mission_experience\", \"information_experience\", \"behavior_experience\"], inplace=True)\n",
    "peer_test_X.drop(columns=[\"mission_experience\", \"information_experience\", \"behavior_experience\"], inplace=True)\n",
    "\n",
    "peer_train_X = np.array(peer_train_X, dtype=\"float32\")\n",
    "peer_test_X = np.array(peer_test_X, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peer_model = make_pipeline(StandardScaler(), TrustVectorEstimator(3))\n",
    "peer_model.fit(peer_train_X, peer_train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peer_predicted_Y = model.predict(peer_test_X)\n",
    "print(r2_score(peer_test_Y, peer_predicted_Y))\n",
    "print(mean_squared_error(peer_test_Y, peer_predicted_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_fact_map_point_state = pd.read_csv(\"demo_data/fact_map_point_state.tsv\", sep=\"\\t\", index_col=[\"time\", \"map_point_id\"])\n",
    "demo_fact_step = pd.read_csv(\"demo_data/fact_step.tsv\", sep=\"\\t\", index_col=[\"start_time\", \"robot_id\"])\n",
    "demo_fact_memory_map_point = pd.read_csv(\"demo_data/fact_memory_map_point.tsv\", sep=\"\\t\", index_col=[\"time\", \"robot_id\", \"x\", \"y\"])\n",
    "demo_dym_map_point = pd.read_csv(\"demo_data/dym_map_point.tsv\", sep=\"\\t\", index_col=[\"id\"])\n",
    "demo_dym_robot = pd.read_csv(\"demo_data/dym_robot.tsv\", sep=\"\\t\", index_col=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMO_BASE_X = 21\n",
    "DEMO_BASE_Y = 28\n",
    "\n",
    "demo_processed_input = process_raw_input_data(DEMO_BASE_X, DEMO_BASE_Y, demo_fact_step)\n",
    "add_trustor_knowledge(demo_processed_input, demo_fact_map_point_state, demo_dym_map_point, demo_fact_memory_map_point)\n",
    "demo_processed_input.to_csv(\"clean_demo_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_past_experience = {robot_id: {\n",
    "    \"mission_experience\": 0.5,\n",
    "    \"information_experience\": 0.5,\n",
    "    \"behavior_experience\": 0.5\n",
    "    } for robot_id in demo_processed_input.index.get_level_values(1).unique()\n",
    "}\n",
    "\n",
    "DEMO_PEER_OPINION = 0.6\n",
    "\n",
    "for (timestamp, robot_id), step in demo_processed_input.iterrows():\n",
    "    model_input = np.hstack([step, list(demo_past_experience[robot_id].values())]).reshape(1, -1)\n",
    "    trust_vector = peer_model.predict(model_input)[0]\n",
    "\n",
    "    peer_opinion = peer_model.predict(model_input)[0]\n",
    "    trust_vector = [v * (DEMO_PEER_OPINION * (p - 1) + 2) / 2 for v, p in zip(trust_vector, peer_opinion)]\n",
    "\n",
    "    demo_past_experience[robot_id][\"mission_experience\"] = trust_vector[0]\n",
    "    demo_past_experience[robot_id][\"information_experience\"] = trust_vector[1]\n",
    "    demo_past_experience[robot_id][\"behavior_experience\"] = trust_vector[2]\n",
    "\n",
    "MISSION_THRESHOLD = 0.8\n",
    "INFORMATION_THRESHOLD = 0.6\n",
    "BEHAVIOR_THRESHOLD = 0.45\n",
    "\n",
    "print(\"Trust decision:\")\n",
    "print(\"ID   MISSION   INFORMATION   BEHAVIOR\")\n",
    "\n",
    "for robot_id, trust_vector in sorted(demo_past_experience.items()):\n",
    "    print(f\"{robot_id:2}   \", end=\"\")\n",
    "    print(\"  YES  \" if trust_vector[\"mission_experience\"] > MISSION_THRESHOLD else \"  NO   \", end=\"   \")\n",
    "    print(\"    YES    \" if trust_vector[\"information_experience\"] > INFORMATION_THRESHOLD else \"    NO     \", end=\"   \")\n",
    "    print(\"  YES   \" if trust_vector[\"behavior_experience\"] > BEHAVIOR_THRESHOLD else \"   NO   \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
